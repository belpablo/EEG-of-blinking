{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC:  0.9171202809482002\n",
      "accuracy for RF:  0.9082089552238806\n",
      "accuracy for kNN:  0.914179104477612\n"
     ]
    }
   ],
   "source": [
    "# реализация по вейвлет-преобразованию\n",
    "\n",
    "import pywt\n",
    "import pylab\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import signal\n",
    "from pylab import *\n",
    "\n",
    "\n",
    "# функция извлечения данных из EDF\n",
    "def data_extraxtion(file_name, chanel_num, start_sec, stop_sec):\n",
    "    \n",
    "    f = pyedflib.EdfReader(file_name)  \n",
    "    n = f.signals_in_file  \n",
    "    signal_labels = f.getSignalLabels() \n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    # частота дискретизации == 125 Гц\n",
    "    x_data = [i for i in range(len(sigbufs[chanel_num]))][start_sec * 125 : stop_sec * 125]\n",
    "    y_data = [sigbufs[chanel_num][i] for i in range(len(sigbufs[chanel_num]))][start_sec * 125 : stop_sec * 125]\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "# функция нахождения координат пиков и левого\\правого концов из конкретного файла по конкретному каналу\n",
    "def peaks_searching(file_name, chanel_num, start_sec, stop_sec):\n",
    "    \n",
    "    _, data_ = data_extraxtion(file_name, chanel_num, start_sec, stop_sec)\n",
    "    \n",
    "    st = 'sym2'        # тип преобразования\n",
    "    lvl = 3           # уровень преобразования (кол-во применений к данному сигналу)\n",
    "    \n",
    "    data = pywt.downcoef('a', data_, st, mode = 'reflect', level = lvl)\n",
    "    abs_max = max(data)\n",
    "    trsh = 0.4\n",
    "    \n",
    "    dots_arr = []\n",
    "    flag = True\n",
    "    tmp = [0] * 5\n",
    "    \n",
    "    for i in range(int(stop_sec - start_sec)): #предполагается, что моргают уж никак не чаще чем раз в секунду\n",
    "\n",
    "        #поиск max:\n",
    "        max_ = max(data)\n",
    "        max_ind =  np.where(data == max_)[0][0]\n",
    "\n",
    "        #поиск min:\n",
    "        min_ = min(data[max_ind : max_ind + 6])\n",
    "        min_ind =  np.where(data == min_)[0][0]\n",
    "        \n",
    "        #если найденный максимум слишком мал\n",
    "        if max_ < 0.3 * abs_max:\n",
    "            flag = False\n",
    "\n",
    "        # если не нашли новой точки\n",
    "        if max_ind == tmp[1]:\n",
    "            flag = False\n",
    "           \n",
    "        # если найденный паттерн не соответствует морганию \n",
    "        if abs(min_/max_) < trsh:\n",
    "            flag = False\n",
    "\n",
    "        #нахождение левого/правого концов пика:\n",
    "        if flag and (min_ * max_ < 0) and (max_ind >= 6) and (min_ind <= len(data) - 6):\n",
    "\n",
    "            for j in range(6):\n",
    "                if data[max_ind - j] < 0.05 * max_:\n",
    "                    left_ind = max_ind - j\n",
    "                    break\n",
    "\n",
    "            for j in range(6):\n",
    "                if data[min_ind + j] > 0.05 * min_:\n",
    "                    right_ind = min_ind + j\n",
    "                    break\n",
    "\n",
    "            #нахождение точки пересения нуля:\n",
    "            zero_pos = max_ind + (min_ind - max_ind) * (max_ / (max_ - min_))\n",
    "\n",
    "            #запись в датафрейм\n",
    "\n",
    "            tmp = [left_ind, max_ind, zero_pos, min_ind, right_ind]\n",
    "            dots_arr.append(tmp)\n",
    "\n",
    "            #обнуляем в копии записи место, в котором нашли пик\n",
    "            data[left_ind : right_ind] = 0\n",
    "            \n",
    "    \n",
    "    columns_ = ['Left', 'Max', 'Zero', 'Min', 'Right'] \n",
    "    index_ = [i for i in range(len(dots_arr))]\n",
    "    \n",
    "    peaks_df = pd.DataFrame(dots_arr, index = index_, columns = columns_)\n",
    "    peaks_df = peaks_df.sort_values('Left').reset_index(drop = True)\n",
    "\n",
    "    #если точки повторяются\n",
    "    for i in range(len(peaks_df)):\n",
    "        if (i >= 1) and ((peaks_df['Right'][i - 1] == peaks_df['Right'][i]) or (peaks_df['Left'][i - 1] == peaks_df['Left'][i])):\n",
    "            peaks_df = peaks_df.drop(index_[i:])\n",
    "            break\n",
    "            \n",
    "    #если точки лежат слишком близко\n",
    "    #for i in range(len(peaks_df)):\n",
    "    #    if (i >= 1) and (peaks_df['Max'][i] - peaks_df['Max'][i - 1] <= 10):\n",
    "    #       peaks_df = peaks_df.drop(index_[i])\n",
    "    #       break\n",
    "           \n",
    "    peaks_df = peaks_df.sort_values('Left').reset_index(drop = True)\n",
    "        \n",
    "    return peaks_df\n",
    "\n",
    "# Точка пересечения нуля\n",
    "def zero_intersection(data, x_1, x_2):\n",
    "    return x_1 + (x_2 - x_1) * ( data[x_1] / (data[x_1] - data[x_2]))\n",
    "\n",
    "\n",
    "# выделение признаков из конкретного файла по конкретному каналу\n",
    "def features_extraction(file_name, chanel_num, start_sec, stop_sec):\n",
    "    \n",
    "    _, data_ = data_extraxtion(file_name + '.edf', chanel_num, start_sec, stop_sec)\n",
    "    \n",
    "    st = 'sym2'        # тип преобразования\n",
    "    lvl = 3           # уровень преобразования (кол-во применений к данному сигналу)\n",
    "    data = pywt.downcoef('a', data_, st, mode = 'reflect', level = lvl)\n",
    "    \n",
    "    peaks_df = peaks_searching(file_name + '.edf', chanel_num, start_sec, stop_sec)\n",
    "    len_df = len(peaks_df)\n",
    "    \n",
    "    columns_ = ['User', 'Max_A', 'Min_A', 'Max_pos', 'Min_pos', 'Left_tan','Center_tan', 'Right_tan', 'Left_s', 'Right_s']\n",
    "    index_ = [i for i in range(len_df)]\n",
    "    features_df = pd.DataFrame(index = index_, columns = columns_)\n",
    "\n",
    "    for i in range(len_df):\n",
    "\n",
    "        features_df['User'][i] = file_name.rstrip(\"_123456\")\n",
    "\n",
    "        features_df['Max_A'][i] = data[peaks_df['Max'][i]]\n",
    "        features_df['Min_A'][i] = data[peaks_df['Min'][i]]\n",
    "\n",
    "        features_df['Max_pos'][i] = peaks_df['Zero'][i] - peaks_df['Max'][i]\n",
    "        features_df['Min_pos'][i] = peaks_df['Min'][i] - peaks_df['Zero'][i]\n",
    "        \n",
    "        features_df['Left_tan'][i] = (data[peaks_df['Max'][i]] - data[peaks_df['Left'][i]]) / (peaks_df['Max'][i] - peaks_df['Left'][i])\n",
    "        features_df['Right_tan'][i] = (data[peaks_df['Right'][i]] - data[peaks_df['Min'][i]]) / (peaks_df['Right'][i] - peaks_df['Min'][i])\n",
    "        features_df['Center_tan'][i] = (data[peaks_df['Min'][i]] - data[peaks_df['Max'][i]]) / (peaks_df['Min'][i] - peaks_df['Max'][i])\n",
    "        \n",
    "        true_pos_left = zero_intersection(data, peaks_df['Left'][i], peaks_df['Max'][i])\n",
    "        true_pos_right = zero_intersection(data, peaks_df['Min'][i], peaks_df['Right'][i])\n",
    "        \n",
    "        features_df['Left_s'][i] = 0.5 * data[peaks_df['Max'][i]] * (peaks_df['Zero'][i] - true_pos_left)\n",
    "        features_df['Right_s'][i] = 0.5 * data[peaks_df['Min'][i]] * (true_pos_right - peaks_df['Zero'][i])\n",
    "    \n",
    "    # преобразуем имена испытуемых\n",
    "\n",
    "    names_arr = np.array(['Pavel', 'Elena', 'Mihail', 'Evgeny'])\n",
    "\n",
    "    for i in range(len(features_df['User'])):\n",
    "        features_df['User'][i] = np.where(names_arr == features_df['User'][i])[0][0] + 1\n",
    "\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# нормализцаия\n",
    "def normalize(df):\n",
    "    \n",
    "    len_df = len(df)\n",
    "    mu = [sum(df[str_]) / len_df for str_ in list(df.columns.values)]\n",
    "    sigma = [np.sqrt(sum((df[str_] - mu[np.where(df.columns.values == str_)[0][0]]) ** 2) / len_df)\\\n",
    "             for str_ in list(df.columns.values)]\n",
    "\n",
    "    #print(len(mu), len(sigma))\n",
    "\n",
    "    for str_ in list(df.columns.values):\n",
    "        if str_ != 'User':\n",
    "            for i in range(len(df[str_])):\n",
    "                current_ind = np.where(df.columns.values == str_)[0][0]\n",
    "                df[str_][i] = (df[str_][i]  - mu[current_ind]) / sigma[current_ind]         \n",
    "    return df\n",
    "\n",
    "\n",
    "# РАБОЧАЯ ЧАСТЬ\n",
    "#names_arr = ['Pavel', 'Elena', 'Mihail', 'Evgeny']\n",
    "names_arr = ['Pavel', 'Evgeny']\n",
    "str_arr = []\n",
    "\n",
    "for str_1 in names_arr:\n",
    "    for str_2 in ['_1', '_2', '_3', '_4', '_5', '_6']:\n",
    "        try:\n",
    "            _, _ =  data_extraxtion(str_1 + str_2 + '.edf', 4, 5, 15)\n",
    "            str_arr.append(str_1 + str_2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "samples_num = len(str_arr)\n",
    "chanel_num_arr = [3, 4]\n",
    "start_sec = 5\n",
    "stop_sec = 55\n",
    "\n",
    "# предобработка + выделение признаков\n",
    "features_df = pd.concat([features_extraction('Pavel_1', i, start_sec, stop_sec) for i in range(3, 5)]).reset_index(drop = True)\n",
    "\n",
    "for i in range(2, samples_num * len(chanel_num_arr)):\n",
    "        \n",
    "    df_curr = features_extraction(str_arr[i // 2], chanel_num_arr[i % 2], start_sec, stop_sec)\n",
    "    features_df = pd.concat([features_df, df_curr]).reset_index(drop = True)\n",
    "            \n",
    "features_df = features_df.sample(frac = 1).reset_index(drop = True)\n",
    "features_df = normalize(features_df)\n",
    "\n",
    "\n",
    "# преобразование типов\n",
    "x_data = [[features_df[features_df.columns[i]][j] for j in range(len(features_df.index))] for i in range(1, len(features_df.columns))]\n",
    "x_data = np.array(x_data).transpose()\n",
    "y_data = list(features_df['User'])\n",
    "\n",
    "\n",
    "# метод опорных векторов с кросс-валиждацией\n",
    "clf_svc_cv = SVC(kernel = 'linear', random_state = 777, C = 1e-1)\n",
    "res_svc = cross_val_score(clf_svc_cv, x_data, y_data, cv = 5)\n",
    "print('accuracy for SVC: ', np.mean(res_svc))\n",
    "\n",
    "\n",
    "# случайный лес с кросс-валидацией\n",
    "clf_rf_cv = RandomForestClassifier(n_estimators = 20, random_state = 42)\n",
    "res_rf = cross_val_score(clf_rf_cv, x_data, y_data, cv=5)\n",
    "print('accuracy for RF: ', np.mean(res_rf))\n",
    "\n",
    "\n",
    "# К ближайших соседей с кросс-валидацией\n",
    "clf_knn_cv = KNeighborsClassifier(n_neighbors = 6)\n",
    "res_knn = cross_val_score(clf_knn_cv, x_data, y_data, cv = 5)\n",
    "print('accuracy for kNN: ', np.mean(res_knn))\n",
    "\n",
    "\n",
    "#для двух человек точность сравнительно неплохая: 90-95%\n",
    "#если брать больше - точность порядка 60 процентов :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC (Default):  0.9411764705882353\n",
      "accuracy for RF (Default):  0.9705882352941176\n",
      "accuracy for kNN (Default):  0.9558823529411765\n"
     ]
    }
   ],
   "source": [
    "# ДЕФОЛТНАЯ кросс-валидация: разделение на train/test\n",
    "\n",
    "trsh = 0.8\n",
    "tmp = int(trsh * len(y_data))\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "x_train = x_data[:tmp]\n",
    "y_train = y_data[:tmp]\n",
    "\n",
    "x_test = x_data[tmp:]\n",
    "y_test = y_data[tmp:]\n",
    "\n",
    "# метод опорных векторов\n",
    "clf_svc_def = SVC(kernel = 'linear', random_state = 777, C = 1)\n",
    "clf_svc_def.fit(x_train, y_train)\n",
    "y_pred = np.array(clf_svc_def.predict(x_test))\n",
    "print('accuracy for SVC (Default): ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# случайный лес\n",
    "clf_rf_def = RandomForestClassifier(n_estimators = 18, max_depth = 5, random_state = 42)\n",
    "clf_rf_def.fit(x_train, y_train)\n",
    "y_pred = np.array(clf_rf_def.predict(x_test))\n",
    "print('accuracy for RF (Default): ', accuracy_score(y_pred, y_test))\n",
    "\n",
    "# k ближайших соседей\n",
    "clf_knn_def = KNeighborsClassifier(n_neighbors = 5)\n",
    "clf_knn_def.fit(x_train, y_train)\n",
    "y_pred = clf_knn_def.predict(x_test)\n",
    "print('accuracy for kNN (Default): ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC (KFold):  0.9260316066725197\n",
      "accuracy for RF (KFold):  0.9140474100087796\n",
      "accuracy for kNN (KFold):  0.9171641791044778\n"
     ]
    }
   ],
   "source": [
    "# используем KFold с 5тью фолдами\n",
    "\n",
    "cv = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    " \n",
    "svc_res_arr = []\n",
    "rf_res_arr = []\n",
    "knn_res_arr = []\n",
    "\n",
    "# метод split возвращает индексы для объектов train и test\n",
    "for train_index, test_index in cv.split(y_data):\n",
    "    \n",
    "    # разделение на train/test\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    # метод опорных векторов\n",
    "    clf_svc_kf = SVC(kernel = 'linear', random_state = 777, C = 1)\n",
    "    clf_svc_kf.fit(x_train, y_train)\n",
    "    svc_res_arr.append(accuracy_score(y_test,  np.array(clf_svc_kf.predict(x_test))))\n",
    "    \n",
    "    # случайный лес\n",
    "    clf_rf_kf = RandomForestClassifier(n_estimators = 18, max_depth = 5, random_state = 42)\n",
    "    clf_rf_kf.fit(x_train, y_train)\n",
    "    rf_res_arr.append(accuracy_score(y_test,  np.array(clf_rf_kf.predict(x_test))))\n",
    "    \n",
    "    # k ближайших соседей\n",
    "    clf_knn_kf = KNeighborsClassifier(n_neighbors = 5)\n",
    "    clf_knn_kf.fit(x_train, y_train)\n",
    "    knn_res_arr.append(accuracy_score(y_test,  np.array(clf_knn_kf.predict(x_test))))\n",
    "    \n",
    "print('accuracy for SVC (KFold): ', np.mean(svc_res_arr))\n",
    "print('accuracy for RF (KFold): ', np.mean(rf_res_arr))\n",
    "print('accuracy for kNN (KFold): ', np.mean(knn_res_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC (KFold):  0.9058823529411765\n",
      "accuracy for RF (KFold):  0.8823529411764705\n",
      "accuracy for kNN (KFold):  0.9117647058823529\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, random_state = 42)\n",
    " \n",
    "svc_res_arr = []\n",
    "rf_res_arr = []\n",
    "knn_res_arr = []\n",
    "\n",
    "# метод split возвращает индексы для объектов train и test\n",
    "for train_index, test_index in cv.split(y_data):\n",
    "    \n",
    "    # разделение на train/test\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    # метод опорных векторов\n",
    "    clf_svc_sp = SVC(kernel = 'linear', random_state = 777, C = 1)\n",
    "    clf_svc_sp.fit(x_train, y_train)\n",
    "    svc_res_arr.append(accuracy_score(y_test,  np.array(clf_svc_sp.predict(x_test))))\n",
    "    \n",
    "    # случайный лес\n",
    "    clf_rf_sp = RandomForestClassifier(n_estimators = 18, max_depth = 5, random_state = 42)\n",
    "    clf_rf_sp.fit(x_train, y_train)\n",
    "    rf_res_arr.append(accuracy_score(y_test,  np.array(clf_rf_sp.predict(x_test))))\n",
    "    \n",
    "    # k ближайших соседей\n",
    "    clf_knn_sp = KNeighborsClassifier(n_neighbors = 5)\n",
    "    clf_knn_sp.fit(x_train, y_train)\n",
    "    knn_res_arr.append(accuracy_score(y_test,  np.array(clf_knn_sp.predict(x_test))))\n",
    "    \n",
    "print('accuracy for SVC (KFold): ', np.mean(svc_res_arr))\n",
    "print('accuracy for RF (KFold): ', np.mean(rf_res_arr))\n",
    "print('accuracy for kNN (KFold): ', np.mean(knn_res_arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
